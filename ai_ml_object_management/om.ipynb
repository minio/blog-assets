{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from typing import Dict, Any\n",
    "\n",
    "from minio import Minio\n",
    "from minio.commonconfig import Filter, Tags\n",
    "from minio.objectlockconfig import ObjectLockConfig, DAYS, GOVERNANCE, YEARS\n",
    "from minio.versioningconfig import VersioningConfig, ENABLED, DISABLED, SUSPENDED\n",
    "from minio.lifecycleconfig import LifecycleConfig, Rule, Expiration, Transition\n",
    "from minio.retention import Retention, GOVERNANCE, COMPLIANCE\n",
    "from minio.error import S3Error\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different ways to create a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket_with_versioning(bucket: str) -> None:\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "    \n",
    "    # Make the bucket if it does not exist.\n",
    "    found = client.bucket_exists(bucket)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket)\n",
    "    client.set_bucket_versioning(bucket, VersioningConfig(ENABLED))\n",
    "\n",
    "\n",
    "def create_bucket_with_locking(bucket: str) -> None:\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "    \n",
    "    # Make the bucket if it does not exist.\n",
    "    found = client.bucket_exists(bucket)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket, object_lock=True)\n",
    "\n",
    "\n",
    "def create_bucket(bucket: str) -> None:\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "    \n",
    "    # Make the bucket if it does not exist.\n",
    "    found = client.bucket_exists(bucket)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df: pd.DataFrame, bucket: str, object_name: str, version_tag: str) -> None:\n",
    "    '''\n",
    "    Function that will save a Pandas dataframe to MinIO.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],  # host.docker.internal\n",
    "                credentials['accessKey'],  \n",
    "                credentials['secretKey'], \n",
    "                secure=False)\n",
    "    tags = Tags(for_object=True)\n",
    "    tags['Version'] = version_tag\n",
    "    encoded_df = df.to_csv(index=False).encode('utf-8')\n",
    "    client.put_object(bucket, object_name, data=io.BytesIO(encoded_df), length=len(encoded_df), content_type='application/csv', tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['06/21/2023', 'New York', 75], ['06/21/2023', 'Boston', 78], ['06/21/2023', 'San Francisco', 69],\n",
    "        ['06/22/2023', 'New York', 79], ['06/22/2023', 'Boston', 82], ['06/22/2023', 'San Francisco', 70]]\n",
    "df = pd.DataFrame(data, columns=['Date', 'City', 'High Temp.'])\n",
    "\n",
    "save_dataframe(df, 'test', 'train.csv', 'v0.001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not work since the OrderedDict that PyTorch creates contains Tensor objects.\n",
    "#json.dumps(model.state_dict(), ensure_ascii=False).encode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: nn.Module, bucket: str, object_name: str, version_tag: str) -> None:\n",
    "    '''\n",
    "    Function that will save a PyTorch Model to MinIO.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],  # host.docker.internal\n",
    "                credentials['accessKey'],  \n",
    "                credentials['secretKey'], \n",
    "                secure=False)\n",
    "    \n",
    "    file_path = os.path.join(tempfile.gettempdir(), 'my_model.pt')\n",
    "    print(file_path)\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "    tags = Tags(for_object=True)\n",
    "    tags['Version'] = version_tag\n",
    "    client.fput_object(bucket, object_name, file_path, content_type='application/octet-stream', tags=tags)\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "save_model(model, 'test', 'my_model.pt', 'v0.001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters(hparams: Dict[str, Any], bucket: str, object_name: str, version_tag: str) -> None:\n",
    "    '''\n",
    "    Function that will save hyperparameters (dictionary) to MinIO.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],  # host.docker.internal\n",
    "                credentials['accessKey'],  \n",
    "                credentials['secretKey'], \n",
    "                secure=False)\n",
    "    \n",
    "    tags = Tags(for_object=True)\n",
    "    tags['Version'] = version_tag\n",
    "    json_data = json.dumps(hparams, ensure_ascii=False).encode('utf8')\n",
    "    client.put_object(bucket, object_name, data=io.BytesIO(json_data), length=len(json_data), content_type='application/json', tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {'epochs': 5,\n",
    "                    'lr': 0.01,\n",
    "                    'batch_size': 50}\n",
    "\n",
    "save_hyperparameters(hyper_parameters, 'test', 'hparams.json', 'v0.001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment(bucket: str, experiment_name: str, model: nn.Module, hparams: Dict[str, Any], df_train: pd.DataFrame, \n",
    "                    df_valid: pd.DataFrame, df_test: pd.DataFrame, version_tag: str) -> None:\n",
    "    # Set up the object names.\n",
    "    hparam_name = f'/{experiment_name}/hparams.json'\n",
    "    df_train_name = f'/{experiment_name}/df_train.csv'\n",
    "    df_valid_name = f'/{experiment_name}/df_valid.csv'\n",
    "    df_test_name = f'/{experiment_name}/df_test.csv'\n",
    "    model_name = f'/{experiment_name}/model.pt'\n",
    "\n",
    "    create_bucket_with_versioning(bucket)    \n",
    "    save_dataframe(df_train, bucket, df_train_name, version_tag)\n",
    "    save_dataframe(df_valid, bucket, df_valid_name, version_tag)\n",
    "    save_dataframe(df_test, bucket, df_test_name, version_tag)\n",
    "    save_model(model, bucket, model_name, version_tag)\n",
    "    save_hyperparameters(hparams, bucket, hparam_name, version_tag)\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "hyper_parameters = {'epochs': 5,\n",
    "                    'lr': 0.01,\n",
    "                    'batch_size': 50}\n",
    "data = [['06/21/2023', 'New York', 75], ['06/21/2023', 'Boston', 78], ['06/21/2023', 'San Francisco', 69],\n",
    "        ['06/22/2023', 'New York', 79], ['06/22/2023', 'Boston', 82], ['06/22/2023', 'San Francisco', 70]]\n",
    "df_train = pd.DataFrame(data, columns=['Date', 'City', 'High Temp.'])\n",
    "df_valid = pd.DataFrame(data, columns=['Date', 'City', 'High Temp.'])\n",
    "df_test = pd.DataFrame(data, columns=['Date', 'City', 'High Temp.'])\n",
    "\n",
    "save_experiment('test-project', 'exp2', model, hyper_parameters, df_train, df_valid, df_test, '0.01')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket Lifecycle Management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bucket_expiration(bucket: str, expire_days: int) -> None:\n",
    "    '''\n",
    "    Function that will set the life cycle rule on a bucket.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "\n",
    "    # Configure life cycle.\n",
    "    config = LifecycleConfig(\n",
    "        [\n",
    "            Rule(\n",
    "                ENABLED,\n",
    "                rule_filter=Filter(prefix=\"/\"),\n",
    "                rule_id=\"remove\",\n",
    "                expiration=Expiration(days=expire_days),\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    client.set_bucket_lifecycle(bucket, config)\n",
    "\n",
    "set_bucket_expiration('test', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bucket_transition(bucket: str, tier_name: str, transition_days: int) -> None:\n",
    "    '''\n",
    "    Function that will set the life cycle rule on a bucket.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "\n",
    "    # Configure life cycle.\n",
    "    config = LifecycleConfig(\n",
    "        [\n",
    "            Rule(\n",
    "                ENABLED,\n",
    "                rule_filter=Filter(prefix=\"/\"),\n",
    "                rule_id=\"transition\",\n",
    "                transition=Transition(days=transition_days, storage_class=tier_name),\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    client.set_bucket_lifecycle(bucket, config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket Level Object Locking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bucket_object_lock(bucket: str, lock_days: int) -> None:\n",
    "    '''\n",
    "    Function that will set the lock configuration on a bucket.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "\n",
    "    # Configure life cycle.\n",
    "    config = ObjectLockConfig(GOVERNANCE, lock_days, DAYS)\n",
    "    client.set_object_lock_config(bucket, config)\n",
    "\n",
    "\n",
    "set_bucket_object_lock(bucket, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_object_lock(bucket: str) -> ObjectLockConfig:\n",
    "    '''\n",
    "    Function that will get the lock configuration on a bucket.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "\n",
    "    duration = (-1, -1)\n",
    "    try:\n",
    "        duration = client.get_object_lock_config(bucket).duration\n",
    "    except S3Error as s3_err:\n",
    "        print(f'S3 Error occurred: {s3_err}.')\n",
    "    except Exception as err:\n",
    "        print(f'Error occurred: {err}.')\n",
    "\n",
    "    return duration\n",
    "\n",
    "get_bucket_object_lock('census-data')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Object Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_object_retention(bucket: str, object_name, days_to_retain: int):\n",
    "    '''\n",
    "    Function that will set the lock retention on an object.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "\n",
    "    # Configure life cycle.\n",
    "    retain_date = datetime.utcnow() + timedelta(days=days_to_retain)\n",
    "    config = Retention(GOVERNANCE, retain_until_date=retain_date)\n",
    "    client.set_object_retention(bucket, object_name, config)\n",
    "\n",
    "set_object_retention('test', 'train.csv', 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legal Hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_object_legal_hold(bucket: str, object_name):\n",
    "    '''\n",
    "    Function that will set a legal hold on an object.\n",
    "    The credentials file must contain the MinIO url, access key, and access secret.\n",
    "    '''\n",
    "    with open('credentials.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    # Create client with access and secret key\n",
    "    client = Minio(credentials['url'],\n",
    "                   credentials['accessKey'],  \n",
    "                   credentials['secretKey'], \n",
    "                   secure=False)\n",
    "\n",
    "    # Set the legal hold.\n",
    "    client.enable_object_legal_hold(bucket, object_name)\n",
    "\n",
    "set_object_legal_hold('test', 'train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
